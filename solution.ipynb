{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6be6114",
   "metadata": {},
   "source": [
    "# Проект: Нейросеть для автодополнения текстов\n",
    "\n",
    "Сравнение LSTM и distilgpt2 для задачи автодополнения коротких текстовых постов.\n",
    "\n",
    "**Датасет:** sentiment140 (короткие текстовые посты, ~1.6M записей)\n",
    "\n",
    "**Задача:** по началу текста (3/4) предсказать продолжение (1/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8e42b6",
   "metadata": {},
   "source": [
    "## Этап 1. Сбор и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654a8f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "from data_utils import load_raw_data, preprocess_dataset, split_dataset\n",
    "\n",
    "df = load_raw_data('data/raw_dataset.txt')\n",
    "print(f'Исходный датасет: {len(df)} строк')\n",
    "\n",
    "df = preprocess_dataset(df)\n",
    "print(f'После очистки: {len(df)} строк')\n",
    "print(df['text'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем и сохраняем (полный датасет)\n",
    "train_df, val_df, test_df = split_dataset(df)\n",
    "df.to_csv('data/dataset_processed.csv', index=False)\n",
    "train_df.to_csv('data/train.csv', index=False)\n",
    "val_df.to_csv('data/val.csv', index=False)\n",
    "test_df.to_csv('data/test.csv', index=False)\n",
    "\n",
    "print(f'Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b81b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from next_token_dataset import create_dataloaders\n",
    "\n",
    "tokenizer, train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    'data/train.csv', 'data/val.csv', 'data/test.csv',\n",
    "    batch_size=64, min_freq=5\n",
    ")\n",
    "\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "print(f'Batch X: {x_batch.shape}, Y: {y_batch.shape}')\n",
    "print(f'Словарь: {tokenizer.vocab_size} слов')\n",
    "\n",
    "# Пример кодирования/декодирования\n",
    "sample = 'i love this movie so much'\n",
    "encoded = tokenizer.encode(sample)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(f'\\nОригинал: {sample}')\n",
    "print(f'Encoded:  {encoded}')\n",
    "print(f'Decoded:  {decoded}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d5e394",
   "metadata": {},
   "source": [
    "## Этап 2. Реализация LSTM модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lstm_model import LSTMModel\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "model = LSTMModel(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    embed_dim=64,\n",
    "    hidden_dim=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "print(f'Параметры модели: {sum(p.numel() for p in model.parameters()):,}')\n",
    "\n",
    "# Проверка forward\n",
    "logits, _ = model(x_batch.to(device))\n",
    "print(f'Logits shape: {logits.shape}')\n",
    "\n",
    "# Проверка генерации (необученная модель)\n",
    "result = model.generate(tokenizer, 'i love this', max_new_tokens=5, device=device)\n",
    "print(f'\\nГенерация (до обучения): {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c0afd4",
   "metadata": {},
   "source": [
    "## Этап 3. Обучение LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac8a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_train import train_model\n",
    "\n",
    "history = train_model(\n",
    "    model, train_loader, val_loader, tokenizer, device,\n",
    "    epochs=10, lr=0.001, save_path='models/lstm_best.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df44ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Графики обучения\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['val_loss'], label='Val')\n",
    "axes[0].set_title('Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(history['rouge1'])\n",
    "axes[1].set_title('ROUGE-1')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].grid(True)\n",
    "\n",
    "axes[2].plot(history['rouge2'])\n",
    "axes[2].set_title('ROUGE-2')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('models/training_history.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418da3f8",
   "metadata": {},
   "source": [
    "### Оценка LSTM на валидации и тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba6bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_train import compute_rouge\n",
    "\n",
    "model.load_state_dict(torch.load('models/lstm_best.pt', map_location=device))\n",
    "\n",
    "print('=== LSTM: Валидация ===')\n",
    "lstm_r1_val, lstm_r2_val, examples_val = compute_rouge(\n",
    "    model, val_loader, tokenizer, device, max_samples=500\n",
    ")\n",
    "print(f'ROUGE-1: {lstm_r1_val:.4f}')\n",
    "print(f'ROUGE-2: {lstm_r2_val:.4f}')\n",
    "print('\\nПримеры:')\n",
    "for ex in examples_val[:5]:\n",
    "    print(f'  Вход:   {ex[\"input\"]}')\n",
    "    print(f'  Таргет: {ex[\"target\"]}')\n",
    "    print(f'  Модель: {ex[\"generated\"]}\\n')\n",
    "\n",
    "print('\\n=== LSTM: Тест ===')\n",
    "lstm_r1_test, lstm_r2_test, examples_test = compute_rouge(\n",
    "    model, test_loader, tokenizer, device, max_samples=500\n",
    ")\n",
    "print(f'ROUGE-1: {lstm_r1_test:.4f}')\n",
    "print(f'ROUGE-2: {lstm_r2_test:.4f}')\n",
    "print('\\nПримеры:')\n",
    "for ex in examples_test[:5]:\n",
    "    print(f'  Вход:   {ex[\"input\"]}')\n",
    "    print(f'  Таргет: {ex[\"target\"]}')\n",
    "    print(f'  Модель: {ex[\"generated\"]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e52b8e",
   "metadata": {},
   "source": [
    "### Примеры свободной генерации LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd481c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    'i love this',\n",
    "    'going to the',\n",
    "    'i am so',\n",
    "    'just got back from',\n",
    "    'why is everyone',\n",
    "    'the weather is',\n",
    "    'i want to',\n",
    "    'happy birthday',\n",
    "]\n",
    "print('Примеры автодополнения (LSTM):\\n')\n",
    "for p in prompts:\n",
    "    result = model.generate(tokenizer, p, max_new_tokens=8, device=device)\n",
    "    print(f'  {p} -> {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed137364",
   "metadata": {},
   "source": [
    "## Этап 4. Предобученный трансформер (distilgpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea523ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_transformer_pipeline import evaluate_transformer\n",
    "\n",
    "print('=== distilgpt2: Валидация ===')\n",
    "gpt_r1_val, gpt_r2_val, gpt_ex_val = evaluate_transformer(\n",
    "    'data/val.csv', max_samples=500\n",
    ")\n",
    "print(f'ROUGE-1: {gpt_r1_val:.4f}')\n",
    "print(f'ROUGE-2: {gpt_r2_val:.4f}')\n",
    "print('\\nПримеры:')\n",
    "for ex in gpt_ex_val[:5]:\n",
    "    print(f'  Вход:   {ex[\"input\"]}')\n",
    "    print(f'  Таргет: {ex[\"target\"]}')\n",
    "    print(f'  Модель: {ex[\"generated\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a8c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== distilgpt2: Тест ===')\n",
    "gpt_r1_test, gpt_r2_test, gpt_ex_test = evaluate_transformer(\n",
    "    'data/test.csv', max_samples=500\n",
    ")\n",
    "print(f'ROUGE-1: {gpt_r1_test:.4f}')\n",
    "print(f'ROUGE-2: {gpt_r2_test:.4f}')\n",
    "print('\\nПримеры:')\n",
    "for ex in gpt_ex_test[:5]:\n",
    "    print(f'  Вход:   {ex[\"input\"]}')\n",
    "    print(f'  Таргет: {ex[\"target\"]}')\n",
    "    print(f'  Модель: {ex[\"generated\"]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a7a36",
   "metadata": {},
   "source": [
    "## Этап 5. Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14b058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сводная таблица метрик\n",
    "print('=' * 70)\n",
    "print(f'{\"Модель\":<15} {\"ROUGE-1 val\":>12} {\"ROUGE-2 val\":>12} {\"ROUGE-1 test\":>13} {\"ROUGE-2 test\":>13}')\n",
    "print('-' * 70)\n",
    "print(f'{\"LSTM\":<15} {lstm_r1_val:>12.4f} {lstm_r2_val:>12.4f} {lstm_r1_test:>13.4f} {lstm_r2_test:>13.4f}')\n",
    "print(f'{\"distilgpt2\":<15} {gpt_r1_val:>12.4f} {gpt_r2_val:>12.4f} {gpt_r1_test:>13.4f} {gpt_r2_test:>13.4f}')\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287689c1",
   "metadata": {},
   "source": [
    "### Анализ\n",
    "\n",
    "1. **Модели показывают сопоставимые результаты** по метрикам ROUGE. LSTM лучше на валидации (ROUGE-1: 0.062 vs 0.054), результаты на тесте близки (ROUGE-1: 0.068 vs 0.070). По ROUGE-2 результаты также сопоставимы.\n",
    "\n",
    "2. **Качество генерации**: Обе модели генерируют грамматически корректные продолжения. LSTM лучше адаптирована к стилю коротких постов, т.к. обучалась именно на них. distilgpt2 генерирует более разнообразный текст, но не всегда попадает в стиль твитов.\n",
    "\n",
    "3. **Причины результата**:\n",
    "   - LSTM обучена на целевом домене (~1.2M коротких постов), что даёт преимущество в метриках на валидации.\n",
    "   - distilgpt2 предобучена на общем корпусе текстов — хорошо знает язык, но не специфику домена.\n",
    "   - Большой объём обучающих данных позволил LSTM хорошо выучить паттерны коротких постов.\n",
    "   - Архитектура трансформера лучше улавливает долгосрочные зависимости, что помогает distilgpt2 на тесте.\n",
    "\n",
    "4. **Размер моделей**:\n",
    "   - LSTM: ~15M параметров (embed_dim=64, hidden_dim=128, словарь ~77K слов).\n",
    "   - distilgpt2: ~82M параметров с subword-токенизацией (BPE), словарь ~50K подслов.\n",
    "\n",
    "### Рекомендации\n",
    "\n",
    "Для данного продукта (соцсеть с короткими постами) рекомендуется **LSTM**, так как:\n",
    "- Сопоставимое качество по метрикам ROUGE при обучении на целевых данных.\n",
    "- Значительно меньший размер (~15M vs ~82M параметров) — проще для мобильных устройств.\n",
    "- Быстрее инференс благодаря меньшему размеру.\n",
    "- Не требует загрузки предобученной модели (~350MB).\n",
    "\n",
    "distilgpt2 может быть предпочтительнее, если:\n",
    "- Нет достаточного объёма данных для обучения LSTM.\n",
    "- Нужна генерация на разнообразные темы за пределами обучающей выборки.\n",
    "- Важна грамматическая корректность на длинных текстах."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
